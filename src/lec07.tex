\documentclass[11pt]{article}

\input{header}

% VARIABLES

\newcommand{\lecturenum}{7}
\newcommand{\lecturetopic}{(non-)NP-Hardness of SVP, CVP}
\newcommand{\scribename}{Yi Ding}

% END OF VARIABLES

\lecheader                      % execute lecture commands

\pagestyle{plain}               % default: no special header

\begin{document}

\thispagestyle{fancy} % first page should have special header

% LECTURE MATERIAL STARTS HERE

In this lecture we will see complexity-theoretic lower and upper bounds for $\svp$ and $\cvp$.
On the one hand, they are $\NP$-hard (under suitable types of reductions) in their exact versions, and even for small approximation factors.
On the other hand, there is good evidence \emph{against} the $\NP$-hardness of their approximate versions for factors $\gamma \geq \sqrt{n/\log n}$.

\section{NP-Hardness of CVP and SVP}%
\label{sec:np-hardness-cvp-svp}

\subsection{NP-Hardness of the Closest Vector Problem}%
\label{sec:np-hardness-cvp}

First let us recall the decisional version of the (approximate) Closest Vector Problem.

\begin{definition}[CVP, decision version]%
  \label{def:gapcvp}
  For an approximation factor $\gamma = \gamma(n) \geq 1$, an instance of $\gapcvp_{1}$ is a basis~$\matB$ of a lattice $\lat = \lat(\matB)$, a target point $\vect \in \R^n$, and a distance $d \in \R$.
  It is a YES instance if $\dist(\vect, \lat) \leq d$, and is a NO instance if $\dist(\vect, \lat) > \gamma \cdot d$.
\end{definition}
The problem is equivalent to asking whether the coset $\vect + \lat$ has an element of length at most $d$ or not.

\begin{theorem}[van Emde Boas~\cite{emde81:_anoth_np}]%
  \label{thm:gapcvp1-np-complete}
  $\gapcvp_{1}$ is $\NP$-complete.
\end{theorem}

\begin{proof}
  To show that a problem is $\NP$-complete, we need to show that it is in $\NP$, and also that it is $\NP$-hard.
  The former is easy: a witness~$w$ for a YES instance $(\matB, \vect, d)$ is a lattice vector $\vecv \in \lat(\matB)$ such that $\length{\vect - \vecv} \leq d$, which by definition exists for a YES instance and does not exist for a NO instance.
  Clearly, the conditions can be efficiently verified.\footnote{One technical subtlety is that the witness must have bit length which is polynomial in the instance length.
    This holds because the bit length of~$\vecv$ is bounded by the sum of those of~$\vect$ and~$d$.}

  Next we need to show $\NP$-hardness, i.e., we need to give a reduction from some $\NP$-hard problem to $\gapcvp_{1}$.
  We reduce from the subset-sum problem, which is a natural choice since it has a very similar linear structure to lattice problems.
  Recall that the subset-sum problem is: given $\veca = (a_1, \ldots, a_n) \in \Z^n$ and $S \in \Z$, decide if there exists $\vecx \in \bit^{n}$ such that $\inner{\veca, \vecx} = \sum_{i=1}^{n} a_{i} x_{i} = S$.
  Our reduction takes a subset-sum instance $(a_1, \ldots, a_n, S)$ as input, and outputs the $\gapcvp_{1}$ instance $(\matB, \vect, d)$, where
  \[ \matB =
    \begin{pmatrix}
      a_1 & a_2 & \cdots & a_n \\
      2 &   &   &   \\
          & 2 &   &   \\
          &   & \ddots &   \\
          &   &   & 2
    \end{pmatrix} \in \Z^{(n+1) \times n}, \quad
    \vect =
    \begin{pmatrix}
      S \\
      1 \\
      1 \\
      \vdots \\
      1
    \end{pmatrix} \in \Z^{n+1}, \quad d = \sqrt{n}. \]

  We need to show that the above is a YES instance of $\gapcvp_{1}$ if and only if the given subset-sum instance is a YES instance.
  In one direction, suppose the subset-sum instance has a solution $\vecx \in \bit^{n}$.
  Then for the lattice vector $\vecv = \matB \vecx$, we have
  \[ \vecv - \vect =
    \begin{pmatrix}
      S \\
      2x_1 \\
      2x_2 \\
      \vdots \\
      2x_n
    \end{pmatrix} -
    \begin{pmatrix}
      S \\
      1 \\
      1 \\
      \vdots \\
      1
    \end{pmatrix} =
    \begin{pmatrix}
      0 \\
      \pm 1 \\
      \pm 1 \\
      \vdots \\
      \pm 1
    \end{pmatrix}, \]
  so $\length{\vecv - \vect} = \sqrt{n}$ and $(\matB, \vect, d)$ is a YES instance of $\gapcvp_{1}$.

  In the other direction, suppose that there exists some lattice vector $\vecv = \matB \vecx$ for $\vecx \in \Z^{n}$ such that $\length{\vecv - \vect} \leq \sqrt{n}$.
  Since the last~$n$ entries of~$\vecv$ are even, the last~$n$ entries of $\vecv-\vect$ are odd, and hence must all be $\pm 1$ because $\length{\vecv-\vect} \leq \sqrt{n}$.
  Therefore, $\vecx \in \bit^{n}$.
  Moreover, the first entry of $\vecv-\vect$ must be zero (against because $\length{\vecv-\vect} \leq \sqrt{n}$), so~$\vecx$ is a solution to the subset-sum instance.
\end{proof}

The above theorem is presented only for the $\ell_2$ norm.
It is not difficult to generalize it to the $\ell_p$ norm for any $p > 1$, including $p = \infty$.

\subsection{NP-Hardness of the Shortest Vector Problem}%
\label{sec:np-hardness-svpinfty}

One might wonder whether similar methods can be used to prove that the decisional Shortest Vector Problem ($\gapsvp_{1}$) is $\NP$-complete.
For the~$\ell_{2}$ norm, it turns out to be \emph{much more challenging} to show this---in fact, it was not until 1998 that Ajtai showed $\NP$-hardness, but under a \emph{randomized} reduction~\cite{DBLP:conf/stoc/Ajtai98}.
This means that an efficient (possibly randomized) algorithm for $\gapsvp_{1}$ would imply that $\NP \subseteq \class{RP}$ (but not necessarily that $\NP = \P$).
Even today, it is still not known whether $\gapsvp_{1}$ in the~$\ell_{2}$ norm is $\NP$-hard under a \emph{deterministic} reduction!

Here we show a much easier result, that $\gapsvp_{1}$ is $\NP$-complete in the $\ell_{\infty}$ norm (also known as max norm), defined as $\length{\vecx}_{\infty} = \max_{i} \abs{x_{i}}$.

\begin{definition}[SVP in $\ell_{\infty}$, decision version]%
  \label{def:gapsvp-inf}
  For an approximation factor $\gamma = \gamma(n) \geq 1$, an instance of $\gapsvp_{\gamma}^{(\infty)}$ is a basis $\matB$ of a lattice $\lat= \lat(\matB)$ and a distance $d \in \R$.
  It is a YES instance if the minimum distance of $\lat$ in $\ell_{\infty}$ norm is at most~$d$, i.e., if $\lambda_{1}^{(\infty)}(\lat) \leq d$, and is a NO instance if $\lambda_{1}^{(\infty)}(\lat) > \gamma \cdot d$.
\end{definition}

\begin{theorem}[van Emde Boas~\cite{emde81:_anoth_np}]%
  \label{thm:gapsvp1-infty}
  $\gapsvp_{1}^{(\infty)}$ is $\NP$-complete.
\end{theorem}

\begin{proof}
  Membership in $\NP$ is easy to see: a witness for instance $(\matB, d)$ is a vector $\vecv \in \lat(\matB)$ for which $\length{\vecv}_{\infty} \leq d$, which can be efficiently checked.
  
  For $\NP$-hardness, we reduce from the $\NP$-hard ``weak partition'' problem, which is a homogeneous variant of the subset-sum problem.
  The weak partition problem is: given $\veca = (a_1, \ldots, a_n) \in \Z^n$, determine whether there exist disjoint sets $X, Y \subseteq \set{1, \ldots, n}$, not both empty, such that $\sum_{i \in X} a_i = \sum_{i \in Y} a_i$.
  Equivalently, it asks whether there is a nonzero $\vecx \in \set{-1, 0, +1}^{n}$ such that $\inner{\veca, \vecx} = 0$.
  (The indices of the $-1$ entries of~$\vecx$ correspond to the elements of~$X$, and the indices of the $+1$ entries correspond to the elements of~$Y$.)

  The reduction works as follows: given an instance $\veca = (a_{1}, \ldots, a_{n})$ of the weak partition problem, it outputs the following instance $(\matB, d)$ of $\gapsvp_{1}^{(\infty)}$:
  \[ \matB =
    \begin{pmatrix}
      2a_1 & 2a_{2} & \cdots & 2a_n \\
      1 & &   &   \\
           & 1 & & \\
           & & \ddots &   \\
           & &  & 1 
    \end{pmatrix} \in \Z^{(n+1) \times n}, \quad d=1. \]

  We need to show that the given weak partition instance is a YES instance if and only if the above $\gapsvp_{1}^{(\infty)}$ instance is a YES instance.
  In one direction, suppose that there exists a nonzero solution $\vecx \in \set{0, \pm 1}^{n}$ to the weak partition instance, so that $\inner{\veca, \vecx} = 0$.
  Then the lattice vector $\matB \vecx \in \lat(\matB)$ is nonzero and has~$\ell_{\infty}$ norm $\length{\matB \vecx}_{\infty} = 1$, as desired.
  In the other direction, suppose there exists a nonzero lattice vector $\vecv = \matB \vecx = \smlmat{2\inner{\veca,\vecx} \\ \vecx} \in \Z^{n+1}$ for $\vecx \in \Z^{n}$ such that $\length{\vecv}_{\infty} \leq 1$.
  The first entry $2\inner{\veca,\vecx}$ of $\vecv$ is even, so it must be zero.
  The remainder of~$\vecv$ is just the vector~$\vecx$, so we must have $\vecx \in \set{0, \pm 1}^{n}$ and $\vecx \neq \veczero$.
  This means that~$\vecx$ is a solution to the weak partition instance, which completes the proof.
\end{proof}

\subsection{Other Results}%
\label{sec:other-results}

As mentioned above, in 1998 Ajtai~\cite{DBLP:conf/stoc/Ajtai98} showed that $\gapsvp_{1}$ in the~$\ell_{2}$ norm is $\NP$-complete under a randomized reduction.
This has since been substantially improved: over a series of works~\cite{DBLP:journals/siamcomp/Micciancio00,DBLP:journals/jacm/Khot05,DBLP:conf/stoc/HavivR07}, it has been shown that $\gapsvp_{c}$ in~$\ell_{2}$ is $\NP$-complete (still under randomized reduction) for any \emph{constant} approximation factor~$\gamma = O(1)$, and even under nearly polynomial factors $\gamma = 2^{\log^{1-\epsilon} n}$ for any constant $\epsilon > 0$ if~$\NP$ cannot be solved in (randomized) quasi-polynomial $2^{\poly(\log n)}$ time.
For CVP, the state of the art is that $\gapcvp_{\gamma}$ is $\NP$-complete under deterministic reduction for factors as large as $\gamma = n^{\Omega(1/{\log\log n})}$~\cite{DBLP:journals/jcss/AroraBSS97}, which is ``almost polynomial'' in~$n$.

A natural question is, how far might we hope to increase the approximation factors $\gamma$ for the $\NP$-hardness of $\gapsvp$ and $\gapcvp$?
There are (at least) two answers:
\begin{enumerate}
\item Clearly, we should not expect to have $\NP$-hardness for very large factors $\gamma \geq 2^n$, because $\gapsvp_{\gamma}$ and $\gapcvp_{\gamma}$ for such factors can be solved in polynomial time using LLL.
\item More interestingly, we should not expect to have $\NP$-hardness for factors $\gamma \geq \sqrt{n/\log n}$.
  We will show why this is the case in the next section.
\end{enumerate}

\section{The Goldreich--Goldwasser Protocol}%
\label{sec:gg-protocol}

\newcommand{\cogapcvp}{\cproblem{coGapCVP}}

Clearly, $\gapcvp_\gamma \in \NP$ for any $\gamma \geq 1$.
To show that $\gapcvp_{\gamma}$ is not likely to be $\NP$-complete for $\gamma \geq \sqrt{n/\log n}$, Goldreich and Goldwasser~\cite{DBLP:journals/jcss/GoldreichG00} proved that it belongs to the complexity class $\coAM$.
That is, the \emph{complement} problem $\cogapcvp_{\gamma}$---which simply flips the YES and NO instances of $\gapcvp_{\gamma}$---is in the class $\AM$ of problems that have ``Arthur--Merlin protocols,'' defined below.

The Goldreich--Goldwasser result is significant because if $\gapcvp_{\gamma}$ was $\NP$-complete for some $\gamma \geq \sqrt{n/\log n}$, then it would follow that $\NP \subseteq \coAM$.\footnote{There are some technical subtleties here related to the fact that $\gapcvp_{\gamma}$ is a \emph{promise} problem, but the chain of reasoning holds for a wide class of reductions by which $\gapcvp_{\gamma}$ might be shown $\NP$-complete.}
It is known that this would imply the collapse of the polynomial-time hierarchy, which is considered very unlikely.
Therefore, this can be considered strong evidence (but not proof!)
that $\gapcvp_{\sqrt{n/\log n}}$ is not $\NP$-complete.

\subsection{$\cogapcvp_{\sqrt{n/\log n}} \in \AM$}%
\label{sec:cogapcvp-in-am}

Informally, the complexity class $\AM$ consists of decision/promise problems for which an unbounded prover can convince an efficient randomized verifier that an instance is a YES instance, but even a (possibly malicious) unbounded prover cannot reliably convince the verifier on a NO instance.

\begin{definition}[$\AM$]
  \label{def:AM}
  A promise problem $L = (L_{\text{YES}}, L_{\text{NO}})$ is in $\AM$ if there exists a constant-round protocol between a probabilistic polynomial-time Turing machine $A$ (``Arthur'') and a computationally unbounded Turing machine $M$ (``Merlin'') with the following properties:
  \begin{itemize}
  \item \emph{Completeness:} for any YES instance $x \in L_{\text{YES}}$, we have that $\Pr[A(x) \leftrightarrow M(x) \text{ accepts}] = 1$, i.e., $M$ always convinces $A$ to accept.

  \item \emph{Soundness:} for any NO instance $x \in L_{\text{NO}}$ and for any unbounded~$M^*$, we have that $\Pr[A(x) \leftrightarrow M^*(x) \text{ accepts}] \leq 1- 1/\poly(\len{x})$, i.e., $A$ rejects with some noticeable probability.
  \end{itemize}
\end{definition}
It is straightforward to show that by repeating the protocol in parallel a polynomial number of times, the ``soundness error'' (i.e., the probability that~$A$ accepts on a NO instance) can be made very small, e.g., $2^{-n}$.

\begin{theorem}[Goldreich--Goldwasser~\cite{DBLP:journals/jcss/GoldreichG00}]%
  \label{thm:gapcvp-coAM}
  $\cogapcvp_{\gamma} \in \AM$ for $\gamma = \sqrt{n/\log n}$ (or more generally, any $\gamma = \Omega(\sqrt{n \log n})$).
\end{theorem}

To prove this theorem, we need to give an Arthur--Merlin protocol which causes Arthur to accept whenever the target point~$\vect$ is \emph{far} from the given lattice~$\lat$, i.e., when all the vectors in the coset $\vect+\lat$ have length more than $\gamma d$ (these are the YES instances of $\cogapcvp$).
On the other hand, when the coset $\vect+\lat$ contains a vector of length at most~$d$ (a NO instance of $\cogapcvp$), Arthur should reject with noticeable probability.
Note that it's not obvious how to convincingly prove the \emph{absence} of a short vector in a lattice coset; this is where \emph{interaction} with an unbounded prover helps.

The intuition behind the protocol is as follows.
Arthur first flips a fair coin.
If it comes up heads, he chooses a ``uniformly random'' point in the lattice~$\lat$; if it comes up tails, he chooses a ``uniformly random'' point in the coset $\vect + \lat$.
Let~$\vecw$ denote the resulting point.
Arthur then randomly chooses uniform ``noise''~$\vece$ from the ball of radius $(\gamma d)/2$, and sends $\vecx = \vecw + \vece$ to Merlin.
Merlin---who, to recall, is computationally unbounded---is supposed to figure out whether Arthur's coin came up heads or not, i.e., whether $\vecw \in \lat$ or $\vecw \in \vect + \lat$.
Under what conditions can Merlin always do this, versus necessarily having some noticeable probability of failing?

Notice that if $\dist(\vect, \lat) \geq \gamma d$, then there is \emph{no overlap} between the balls centered at the points of~$\lat$ and ones centered at the points of $\vect + \lat$, so Merlin can always give the correct answer.
On the other hand, if $\dist(\vect, \lat) \leq d$, we will argue that the \emph{overlap} between the two collections of balls is relatively large, hence Merlin must make a mistake with some noticeable probability.
We now formalize the protocol and its analysis to prove the theorem.
In particular, we eliminate the (mathematically problematic) need for a ``uniformly random'' lattice point by working \emph{modulo the lattice}, using the fundamental parallelepiped of the input basis as a fundamental region.

\begin{proof}[Proof of \cref{thm:gapcvp-coAM}]
  The Arthur--Merlin protocol is as follows.
  Arthur and Merlin are given some $\cogapcvp$ instance $(\matB, \vect, d)$ as input.
  Arthur chooses a bit $b \in \bit$ and $\vece \leftarrow r \bar{\cal{B}}$ uniformly at random, where $r = (\gamma d/2)$ and $\bar{\cal{B}}$ is the closed unit ball.
  Arthur then sends the vector
  \[ \vecx := (b\cdot \vect + \vece) \bmod \matB \] to Merlin,
  i.e.,~$\vecx$ is the unique element of
  $(b \vect + \vece + \lat(\matB)) \cap \piped(\matB)$ (which is easy
  to compute). If $\dist(\vecx, \lat) \leq r$, Merlin returns
  $b' = 0$; otherwise he returns $b'=1$. Arthur accepts if $b' = b$.

  First we show completeness.
  Let $(\matB, \vect, d)$ be a YES instance of $\cogapcvp_{\gamma}$, so $\dist(\vect, \lat) > \gamma d$ where $\lat=\lat(\matB)$.
  By the triangle inequality, for \emph{any} $\vecx \in \R^{n}$, at most one of $\dist(\vecx, \lat) \leq r$ and $\dist(\vecx - \vect, \lat) \leq r$ can hold.
  When $b=0$, we have $\vecx = \vece \bmod \matB$, so $\dist(\vecx,\lat) = \dist(\vece,\lat) \leq r$, hence Merlin correctly returns $b'=0$.
  Similarly, when $b=1$, we have $\vecx = \vect + \vece \bmod \matB$, so $\dist(\vecx - \vect, \lat) \leq r$, so $\dist(\vecx,\lat) > r$ and Merlin correctly return $b'=1$.

  Proving soundness is more involved.
  Let $(\matB, \vect, d)$ be a NO instance, so $\dist(\vect,\lat) \leq d$ where $\lat=\lat(\matB)$; we need to show that Merlin answers incorrectly with some noticeable $1/\poly(n)$ probability.

  To see this, let $\vecv \in \lat$ be a lattice vector for which $\length{\vect'} \leq d$ where $\vect' = \vect - \vecv$.
  Now observe that Arthur's message~$\vecx$ in the protocol is \emph{identically distributed} to one generated in a slightly different way in the case $b=1$, as $\vecx := \vect' + \vece \bmod \matB$ (the case $b=0$ is unchanged).
  This is simply because $\vect' + \vece \bmod \matB$ equals $\vect + \vece \bmod \matB$ for any $\vecv \in \lat$ and $\vece \in \R^{n}$.
  Now let $I = r \bar{\cal{B}} \cap (\vect' + r \bar{\cal{B}})$ be the intersection of the balls centered at the origin and at~$\vect'$, and observe that for any $\vecy \in I$ (even before reducing modulo~$\matB$), it is equally likely that Arthur chose $b=0$ and $\vece=\vecy$ versus $b=1$ and $\vece=\vecy-\vect'$.\footnote{This is not quite rigorous, because we are conditioning on an event of probability zero.
    This can be fixed by instead using measure.}
  So, in this case Merlin cannot do any better than a random guess, which succeeds with probability~$1/2$.
  Therefore, the probability that Merlin answers incorrectly is at least half of
  \begin{equation}
    \label{eq:ratio-ball-intersection}
    \frac{\vol(r \bar{\cal{B}} \cap (\vect' + r
      \bar{\cal{B}}))}{\vol(r \bar{\cal{B}})} .
  \end{equation}

  Therefore, it suffices to give a lower bound on the above quantity, which by rescaling is the fraction of overlap between two $n$-dimensional balls of unit radius whose centers are $\delta \leq 2/\gamma$ apart.
  It is not hard to see that the intersection contains a cylinder~$C$ with radius $\sqrt{1-\delta^2}$ and height~$\delta$.
  The volume of an $n$-dimensional unit ball is known to be
  \[ V_n = \frac{\pi^{n/2}}{(n/2)!} , \] where the generalized
  factorial function satisfies $0! = 1$, $n! = n(n-1)!$ for all real
  $n \geq 1$, and $(1/2)! = \sqrt{\pi}$. We also need the fact that
  $(n+\frac{1}{2})!/{n!} = \Theta(\sqrt{n})$.

  Therefore, the quantity in \cref{eq:ratio-ball-intersection} is at least
  \begin{align*}
    \frac{\delta \cdot (1-\delta^{2})^{(n-1)/2} \cdot V_{n-1}}{V_{n}}
    &= \frac{\delta \cdot (1-\delta^{2})^{(n-1)/2} \cdot \pi^{(n-1)/2}
      \cdot (n/2)!}{(n/2-1/2)! \cdot \pi^{n/2}} \\
    &= (1-\delta^{2})^{(n-1)/2} \cdot \Theta(\delta \sqrt{n}).
  \end{align*}
  
  Recalling that $(1-1/n)^n = 1/O(1)$ (indeed, it approaches $1/e$ as~$n$ grows), we have $(1 - (\log n)/n)^{n} = 1/O(1)^{\log n} = 1/\poly(n)$.
  So for any $\delta = O(\sqrt{(\log n)/n})$ and hence any $\gamma = \Omega(\sqrt{n/\log n})$, the above quantity is $1/\poly(n)$, as needed.
\end{proof}

\subsection{Summary}

To summarize:
\begin{itemize}
\item $\gapcvp_{n^{1/\log \log n}}$ is $\NP$-complete.
\item $\gapcvp_{\sqrt{n/\log n}} \in \coAM$, so it is unlikely to be
  $\NP$-hard.
\item A work of Aharonov and Regev~\cite{DBLP:journals/jacm/AharonovR05} (which we will cover later in this course) showed that $\gapcvp_{\sqrt{n}}$ is in $\coNP$, and hence is unlikely to be $\NP$-hard.
\item $\gapcvp_{2^n}$ is in~$\P$, due to the LLL algorithm.
\end{itemize}
% From Gap-CVP$_{n}$ to Gap-CVP$_{2^n}$ is where we can
% construction cryptosystems.
% Meanwhile finding the right boundary of
% $\gamma$ between ${n^{\frac{1}{\log \log n}}}$ and
% ${\sqrt{\frac{n}{\log n}}}$ that transforms Gap-CVP$_{\gamma}$ from
% NP-complete to most unlikely NP-complete is still an open question.

\bibliography{common/lattices,common/crypto}
\bibliographystyle{common/alphaabbrvprelim}

\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
